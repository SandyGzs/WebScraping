"""
Objective: finding all store contact informations for any store in 
(1) "https://www.yiwugo.com/shop_list/i_1_1003.html" China Yiwu International Trade City Phase III
(2) "https://www.yiwugo.com/shop_list/i_1_1001.html" China Yiwu International Trade City Phase I 3rd & 4th floor 

It's very easy to see that the url is in the format f"https://www.yiwugo.com/shop_list/i_1_100{floor_number}" where floor number can be 1, 2, 3 or more.

Difficulty:
(1) if visiting speed is faster than 4s per refresh, browser is located and forced login + text verification are triggered [future goals]
(2) limited search results: i. search subpages ii. find open api endpoints

Please prepare the setup of DrissionPage and Chrome
"""

# Version I
# Import Packages
from DrissionPage import ChromiumPage, ChromiumOptions 
import pandas as pd
from tqdm import tqdm
import re

# Prepare Chrome
co = ChromiumOptions().auto_port()
co.headless()
driver = ChromiumPage(co)

# Choose which url groups you need - let's use Objective (2) as an example
driver.get("https://www.yiwugo.com/shop_list/i_1_1001.html")
urls = [ 
    ele.attr("href")
    for ele in driver.s_ele(".markets-wrap").children() 
    if ele.attr("href") and re.compile(r"https://www.yiwugo.com/shop_list/i_1_1001_(3|4)").match(ele.attr("href")) 
]


# Core Action: Get Data
def getData(chrome_driver):
    driver.wait.ele_loaded(".shop-list")
    return pd.DataFrame([
        {"title": pic.s_ele(".shop-name").attr("title"), "href": pic.s_ele(".shop-name").attr("href")} 
        for pic in driver.s_ele(".shop-list").children() 
        if pic.attr("class") == 'pro_list_company_img'
    ])


# Start WebScraping
dfs = []
for url in tqdm(urls):
    driver.get(url)
    driver.wait.ele_loaded(".ant-pagination-simple-pager")
    pages = driver.s_ele(".ant-pagination-simple-pager")
    pages = int(driver.s_ele(".ant-pagination-simple-pager").attr("title").split("/")[1]) - 1 if pages else 0
    dfs.append(getData(driver))
    if pages > 1:
        for _ in range(pages):
            driver.wait(5)
            driver.wait.ele_loaded(". ant-pagination-next")
            driver.ele(". ant-pagination-next").click()
            dfs.append(getData(driver))

# Save DataFrame
pd.concat(dfs).to_csv("ywg_targets.csv", index=False)

# Get Stored Data
df = pd.read_csv("ywg_targets.csv")
urls = df["href"].values.tolist()


# Get URL Info
def get_url(target_url):
    driver.get(target_url)
    driver.wait(4)
    dictionary = {
        "company": None, "phone": None, "telephone": None, "wechat": None, "email": None, "location": None
    }
    dictionary_ele = {
        "company": '.temp-company-v', 
        "phone": '.iconfont iconshouji1', 
        "telephone": '.iconfont icondianhua-F', 
        "wechat": '.anticon anticon-wechat', 
        "email": '.iconfont iconxinfengtianchong', 
        "location": '.lh16 map listFlex'
    }
    for k, v in dictionary_ele.items():
        driver.wait.ele_loaded(v)
        ele = driver.s_ele(v)
        if ele:
            if k == "company":
                dictionary[k] = ele.child(1).text
            elif k == "location":
                dictionary[k] = ele.text
            else:
                dictionary[k] = ele.parent(1).text
    return dictionary


# Save DataFrame
pd.DataFrame([get_url(url) for url in tqdm(urls)]).to_csv("ywg_data.csv", index=False)
driver.quit()
