"""
Objective: finding all store contact informations for any store in 
(1) "https://www.yiwugo.com/shop_list/i_1_1003.html" China Yiwu International Trade City Phase III
(2) "https://www.yiwugo.com/shop_list/i_1_1001.html" China Yiwu International Trade City Phase I 3rd & 4th floor 

It's very easy to see that the url is in the format f"https://www.yiwugo.com/shop_list/i_1_100{floor_number}" where floor number can be 1, 2, 3 or more.

Difficulty:
(1) if visiting speed is faster than 4s per refresh, browser is located and forced login + text verification are triggered [future goals] -> user-agent recognization
(2) limited search results: i. search subpages ii. find open api endpoints

Please prepare the setup of DrissionPage and Chrome
"""

# Version I
# Import Packages
from DrissionPage import ChromiumPage, ChromiumOptions 
import pandas as pd
from tqdm import tqdm
import re
from random_user_agent.user_agent import UserAgent
from random_user_agent.params import SoftwareName, OperatingSystem
from concurrent.futures import ThreadPoolExecutor

# Prepare Chrome
co = ChromiumOptions().auto_port()
co.headless()
driver = ChromiumPage(co)

# Prepare User Agents
software_names = [SoftwareName.CHROME.value]
operating_systems = [OperatingSystem.MAC.value]   
user_agent_rotator = UserAgent(software_names=software_names, operating_systems=operating_systems, limit=100)

# Choose which url groups you need - let's use Objective (2) as an example
driver.get("https://www.yiwugo.com/shop_list/i_1_1001.html")
driver.wait.ele_loaded(".markets-wrap")
urls = [ 
    ele.attr("href")
    for ele in driver.s_ele(".markets-wrap").children() 
    if ele.attr("href") and re.compile(r"https://www.yiwugo.com/shop_list/i_1_1001_(3|4)").match(ele.attr("href")) 
]
driver.quit()


# Core Action: Get Data
def getData(chrome_driver):
    chrome_driver.wait.ele_loaded(".shop-list")
    return pd.DataFrame([
        {"title": pic.s_ele(".shop-name").attr("title"), "href": pic.s_ele(".shop-name").attr("href")} 
        for pic in chrome_driver.s_ele(".shop-list").children() 
        if pic.attr("class") == 'pro_list_company_img'
    ])


# Finish Each Loop
def loop_url(target_url):
    tmp = []
    co = ChromiumOptions().auto_port()
    co.set_user_agent(user_agent=user_agent_rotator.get_random_user_agent())
    co.headless()
    driver = ChromiumPage(co)
    driver.get(target_url)
    driver.wait.ele_loaded(".ant-pagination-simple-pager")
    pages = driver.s_ele(".ant-pagination-simple-pager")
    pages = int(driver.s_ele(".ant-pagination-simple-pager").attr("title").split("/")[1]) - 1 if pages else 0
    tmp.append(getData(driver))
    if pages > 1:
        for _ in range(pages):
            driver.wait(5)
            driver.wait.ele_loaded(". ant-pagination-next")
            driver.ele(". ant-pagination-next").click()
            tmp.append(getData(driver))
    driver.quit()
    return pd.concat(tmp)
    

# Start WebScraping
stack = []
with ThreadPoolExecutor(max_workers=5) as executor:
    stack = list(tqdm(executor.map(loop_url, urls), total=len(urls)))

# Save DataFrame
pd.concat(stack).to_csv("ywg_targets.csv", index=False)

# Get Stored Data
df = pd.read_csv("ywg_targets.csv")
urls = df["href"].values.tolist()
stack = []

# Get URL Info
def get_url(target_url):
    co = ChromiumOptions().auto_port()
    co.set_user_agent(user_agent=user_agent_rotator.get_random_user_agent())
    co.headless()
    driver = ChromiumPage(co)
    driver.get(target_url)
    dictionary = {
        "company": None, "phone": None, "telephone": None, "wechat": None, "email": None, "location": None
    }
    dictionary_ele = {
        "company": '.temp-company-v', 
        "phone": '.iconfont iconshouji1', 
        "telephone": '.iconfont icondianhua-F', 
        "wechat": '.anticon anticon-wechat', 
        "email": '.iconfont iconxinfengtianchong', 
        "location": '.lh16 map listFlex'
    }
    for k, v in dictionary_ele.items():
        driver.wait.ele_loaded(v)
        ele = driver.s_ele(v)
        if ele:
            if k == "company":
                dictionary[k] = ele.child(1).text
            elif k == "location":
                dictionary[k] = ele.text
            else:
                dictionary[k] = ele.parent(1).text
    driver.quit()
    return dictionary


# Process
with ThreadPoolExecutor(max_workers=5) as executor:
    stack = list(tqdm(executor.map(get_url, urls), total=len(urls)))

# Save DataFrame
pd.DataFrame(stack).to_csv("ywg_data.csv", index=False)
